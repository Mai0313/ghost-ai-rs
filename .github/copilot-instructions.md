Ghost AI â€“ Developer Instructions

This document captures technical notes relevant to contributors.

Model list loading and config updates

- Renderer-side model selectors live in both `src/components/AskPanel.tsx` (next to the Ask input) and `src/components/Settings.tsx` (in the OpenAI Settings section).
- Both selectors are synchronized and use the same API calls to maintain consistency.
- Models are fetched through `window.ghostAI.listOpenAIModels()` which bridges to `ipcMain.handle('openai:list-models')` and ultimately `src/shared/openai-client.ts#listModels`.
- To avoid the selector getting stuck on "Loading modelsâ€¦" when the API key is missing or invalid, `listModels()` now returns a sensible default list even on errors.

IPC updates

- New broadcast event: `openai:config-updated`.
  - Emitted by main after both `openai:update-config` (persisted) and `openai:update-config-volatile` (in-memory) updates.
  - Main implementation lives in `src/main/main.ts`.
  - Preload exposes a convenience listener: `onOpenAIConfigUpdated(handler)` in `src/main/preload.ts`.
  - Renderer subscribes and refreshes the model list when config changes (see `src/components/AskPanel.tsx`).

// Removed: settings:updated broadcast and preload listener to keep surface minimal.

OpenAI client behavior

- `src/shared/openai-client.ts#listModels()`:
  - Tries to call `client.models.list()`.
  - Filters to an allowed ordering when available.
  - On any exception, returns the same default allowed order so the UI remains usable.

Renderer notes

- Both the Ask footer model selector and Settings model selector now refresh automatically when settings change, via `onOpenAIConfigUpdated`.
- Settings screen (`src/components/Settings.tsx`)
  - Loads once on mount; remains mounted while you toggle visibility, avoiding reload on each open.
  - Subscribes to `onOpenAIConfigUpdated` and (local save) updates to refresh state only on real updates.
  - Contains a model selector in the OpenAI Settings section that is synchronized with the Ask panel selector.
  - **Optimized config loading (2024-12-19)**:
    - Added debounced model refresh (800ms) when API key or base URL changes to prevent excessive API calls
    - Improved loading states with `loadingConfig` and `loadingModels` indicators
    - Enhanced error handling with proper try-catch blocks and console warnings
    - Optimized initial loading with `useCallback` hooks to prevent unnecessary re-renders
    - Added change detection to avoid redundant model updates when values haven't actually changed
    - Better cleanup of event listeners and debounce timeouts

Ask panel notes

- `src/components/AskPanel.tsx` is kept mounted; App toggles visibility via CSS to avoid reloading the model list on each open.
- Model list fetch happens on mount and when `onOpenAIConfigUpdated` fires (API key/baseURL/model changes), not on every toggle.
- **Screenshot attachment toggle (2024-12-19)**:
  - Added screenshot toggle button (ğŸ“·) next to the input field in AskPanel footer
  - Toggle state is synchronized between AskPanel and Settings page via App component state management
  - Changes are immediately persisted to user settings via `updateUserSettings({ attachScreenshot })`
  - Both UI locations reflect the same state and update each other in real-time

Troubleshooting

- If requests fail after selecting a model, verify that your OpenAI API key has access to that model and that `baseURL` is correct.
- Use the Settings screen "Test" button to validate API connectivity.

### Packaging/runtime specifics

- Renderer asset base path
  - Vite must use a relative base when serving via `file://` in Electron.
  - Set `base: './'` in `vite.config.ts` so `dist/renderer/index.html` references assets relatively.
- Dev/prod detection in main
  - Use `app.isPackaged` instead of `process.env.NODE_ENV` to distinguish packaged runtime.
  - In production, load `path.join(__dirname, 'renderer', 'index.html')`; in dev, load `http://localhost:5173`.
- Symptom: packaged app installs but shows no UI
  - Likely due to incorrect `base` or dev detection. Apply the two fixes above, rebuild, then repackage.

## Ghost AI â€“ Developer Notes

This document explains technical behaviors relevant to contributors.

### Prompt Injection Behavior

- The active default prompt is stored in `~/.ghost-ai/prompts/default.txt`.
- It is injected into the first turn of each session only.
- Subsequent turns for the same `sessionId` omit the default prompt to avoid duplicative instructions.

Implementation details:

- `src/main/modules/session-store.ts` exposes `hasEntries(sessionId: string): boolean`.
- `src/main/main.ts` checks `!sessionStore.hasEntries(requestSessionId)` to decide whether to read and pass the default prompt.
- The call site:

```ts
// Load active prompt content only for the first turn of the current session
const defaultPrompt = (() => {
  try {
    const isFirstTurn = !sessionStore.hasEntries(requestSessionId);
    if (!isFirstTurn) return "";
    return readPrompt() || "";
  } catch {
    return "";
  }
})();
if (defaultPrompt) initialPromptBySession.set(requestSessionId, defaultPrompt);
```

### Conversation Memory

- Plainâ€‘text `Q:`/`A:` history is maintained in the main process per session using a Map: `conversationHistoryBySession: Map<string, string>`.
- The initial (firstâ€‘turn) default prompt used for a session is cached in `initialPromptBySession: Map<string, string>` and reused when rebuilding history for regeneration.
- On each new request, `combinedTextPrompt` is composed as:

```ts
// Use override if provided (regeneration), otherwise use accumulated history
const priorPlain =
  (typeof payload.history === "string" ? payload.history : null) ??
  conversationHistoryBySession.get(requestSessionId) ??
  "";

const initialPromptPrefix = initialPromptBySession.get(requestSessionId) ?? "";

const priorWithInitial =
  typeof payload.history === "string"
    ? `${initialPromptPrefix}${priorPlain || ""}`
    : priorPlain;

const combinedTextPrompt = priorWithInitial
  ? `Previous conversation (plain text):\n${priorWithInitial}\n\nNew question:\n${(payload.textPrompt ?? "").trim()}`
  : (payload.textPrompt ?? "").trim();
```

### Sessions

- A top-level `currentSessionId` is created on app start and when Ask is cleared or a new session is requested.
- Session entries are appended via `sessionStore.appendEntry` and persisted under `~/.ghost-ai/logs/<sessionId>/<sessionId>.json` for debugging/inspection.

### Streaming Only

- The app uses streaming analysis only (`capture:analyze-stream` IPC). Legacy non-streaming paths were removed.

# Ghost AI - Developer Instructions (Copilot)

This document describes important technical details for contributors. Update this whenever you change IPC channels, main/renderer contracts, or shared types.

## Architecture Overview

- Electron main process (`src/main/*`) handles:
  - Global hotkeys, tray, window lifecycle
  - OpenAI requests via `src/shared/openai-client.ts`
  - Screenshot capture via `src/main/modules/screenshot-manager.ts`
  - Settings persistence via `electron-store`
- Renderer (UI files under `src/*`) is a lightweight HUD and settings UI built with React
- Shared types and the OpenAI client are in `src/shared/*`

- Maintenance: Removed unused stubs `src/services/audio-processor.ts` and `src/services/image-processor.ts`.

## OpenAI Integration

- Wrapper class: `src/shared/openai-client.ts`
  - `initialize`, `updateConfig`, `validateConfig`, `listModels`
  - Streaming only: `completionStream(imageBuffer, textPrompt, customPrompt, requestId, onDelta)`
    - `onDelta` signature: `{ channel: 'answer'; delta?: string; text?: string; eventType: string }`
    - This path does not emit reasoning or tool events; only answer deltas/done.
  - Removed legacy helpers and Conversations helpers: `chatCompletion(...)`, `analyzeWithHistoryStream(...)`, `createConversation(...)`, `retrieveConversationItems(...)`.

### Reasoning stream (Responses API)

- `responseStream` forwards reasoning events in addition to answer deltas.
- Handled event types: `response.reasoning_summary_part.added`, `response.reasoning_summary_part.done`, `response.reasoning_summary_text.delta`, `response.reasoning_summary_text.done`.
- The delta callback now receives `{ channel: 'answer' | 'reasoning', eventType, delta?, text? }`.
  - Additionally supports `{ channel: 'web_search' }` with `eventType` in
    `response.web_search_call.in_progress|searching|completed`.
  - Main relays these via `capture:analyze-stream:delta` with the same fields.
  - Preload preserves the fields for renderer `onDelta`.
  - Renderer renders reasoning in a smaller, translucent area above the main answer and streams it live.
  - UI labels: a small "Reasoning" label appears above the reasoning block, and a small "Answer" label appears above the final answer markdown for clarity.

Notes:

- The project pins neither OpenAI SDK version nor strict types (uses `@ts-ignore` at call-sites as the SDK frequently changes). Keep the mapping minimal and guarded.
- Vision is implemented through `chat.completions.create` with a `content` array of `[text, image_url]`.
- To maximize model compatibility, we DO NOT set `temperature` or `max_tokens`/`max_completion_tokens` in API calls. Let the model defaults apply. If you re-introduce these, guard per-model support.
- For `gpt-5` only, we set `reasoning_effort: 'low'` on chat completion requests. Do not send `reasoning_effort` to nonâ€‘`gpt-5` models as many do not support it.

Type notes (OpenAIConfig):

- `src/shared/types.ts` defines `OpenAIConfig`.
- Field `maxTokens` is kept for configurability but not sent to the API by default.
- Type: `maxTokens?: number | null`.
- Default: `null` (see `src/main/main.ts#initializeOpenAI`). Treat `null` as "use model default / maximum".
- If you re-introduce explicit token limits at call sites, only include the parameter when `typeof maxTokens === 'number'`; when `null` or `undefined`, omit the param entirely to preserve model defaults.

## IPC Contracts

Preload exposes `window.ghostAI` via `src/main/preload.ts`:

```ts
interface GhostAPI {
  updateOpenAIConfig(cfg: Partial<OpenAIConfig>): Promise<boolean>;
  getOpenAIConfig(): Promise<OpenAIConfig | null>;
  validateOpenAIConfig(cfg: OpenAIConfig): Promise<boolean>;
  listOpenAIModels(): Promise<string[]>;
  analyzeCurrentScreenStream(
    textPrompt: string,
    customPrompt: string,
    handlers: {
      onStart?: (p: { requestId: string; sessionId: string }) => void;
      onDelta?: (p: {
        requestId: string;
        sessionId: string;
        channel?: "answer" | "reasoning";
        eventType?: string;
        delta?: string;
        text?: string;
      }) => void;
      onDone?: (p: AnalysisResult & { sessionId: string }) => void;
      onError?: (p: {
        requestId?: string;
        error: string;
        sessionId: string;
      }) => void;
    },
    history?: string | null, // optional plain-text Q/A prior-context override (used for regeneration)
  ): () => void; // unsubscribe
  // Realtime transcription (WS)
  startTranscription(options: { model?: string }): Promise<{ ok: boolean }>;
  appendTranscriptionAudio(base64Pcm16: string): void;
  endTranscription(): void;
  stopTranscription(): void;
  onTranscribeStart(
    handler: (p: { ok: boolean; sessionId: string }) => void,
  ): () => void;
  onTranscribeDelta(
    handler: (p: { delta: string; sessionId: string }) => void,
  ): () => void;
  onTranscribeDone(
    handler: (p: { content: string; sessionId: string }) => void,
  ): () => void;
  onTranscribeError(
    handler: (p: { error: string; sessionId: string }) => void,
  ): () => void;
  onTranscribeClosed(handler: () => void): () => void;
  getUserSettings(): Promise<any>;
  updateUserSettings(partial: Partial<any>): Promise<any>;
  onTextInputShow(handler: () => void): void;
  onTextInputToggle(handler: () => void): void; // toggles Ask panel open/closed
  onHUDShow(handler: () => void): void; // Emitted when HUD should become visible again (e.g., after toggling hide)
  toggleHide(): Promise<true>; // IPC to toggle main-process hidden state
  onAudioToggle(handler: () => void): void;
  // Toggle native click-through for the transparent overlay window
  setMouseIgnore(ignore: boolean): Promise<true>;
}
```

## Prompts Management (Read-only)

- Prompts are stored under `~/.ghost-ai/prompts`.
- The app NEVER writes or overwrites any prompt files. Selection is persisted by name in user settings (`defaultPrompt`).
- There is NO fallback to `default.txt`. An active prompt must be selected in Settings â†’ Prompts; otherwise analyze is blocked with an explicit error.
- Main module: `src/main/modules/prompts-manager.ts`
  - `listPrompts()`, `readPrompt(name?)` (reads selected or explicit name)
  - `setDefaultPromptFrom(name)` and `setActivePromptName(name)` now only persist the selected name (no file writes)
  - `getActivePromptName()` returns the persisted name; `getDefaultPromptName()` is legacy
- IPC handlers in main: `prompts:list`, `prompts:read`, `prompts:set-default`, `prompts:get-default`, `prompts:get-active`, `prompts:set-active`
- Preload surface:

```ts
listPrompts(): Promise<{ prompts: string[]; defaultPrompt: string | null }>;
readPrompt(name?: string): Promise<string>;
setDefaultPrompt(name: string): Promise<string>; // persist name only
getDefaultPrompt(): Promise<string | null>;
getActivePromptName(): Promise<string | null>;
setActivePromptName(name: string): Promise<string>;
```

Renderer Settings UI lists available files and sets the active prompt; creating/editing/deleting prompt files is done outside the app.

Analyze flow: on first turn only, main reads the selected prompt by name and injects it. If none is selected, main emits an error and aborts the analyze request.

Main-side handlers in `src/main/main.ts` (streaming only):

- `ipcMain.on('capture:analyze-stream', ...)`
- `ipcMain.handle('hud:set-mouse-ignore', (evt, ignore) => mainWindow.setIgnoreMouseEvents(ignore, { forward: true }))`
- Hotkey handler emits `text-input:toggle` to renderer on `Cmd/Ctrl+Enter` to toggle Ask panel
  - To avoid overlap with `Cmd/Ctrl+Shift+Enter` (voice), the main process suppresses Ask toggles within ~400ms after a voice toggle.
- Emits to renderer:
  - `capture:analyze-stream:start` with `{ requestId, sessionId }` (sessionId required)
  - `capture:analyze-stream:delta` with `{ requestId, sessionId, channel?, eventType?, delta?, text? }`
  - `capture:analyze-stream:done` with final `AnalysisResult & { sessionId }` (sessionId required)
  - `capture:analyze-stream:error` with `{ requestId?, error, sessionId }` (sessionId required)

Streaming cancellation (interrupt):

- The main process now tracks per-renderer AbortControllers for analyze streams. On `Cmd/Ctrl+R` (clear), main aborts the active stream for that renderer, emits `ask:clear`, resets conversation history, generates a new `sessionId`, and broadcasts `session:changed`.
- Renderer must unsubscribe any active stream listeners upon `ask:clear` or `session:changed` and reset its UI state (`streaming=false`, clear `requestId`, `result`, input `text`, stop recording, etc.).
- The OpenAI client (`openai-client.ts`) accepts an optional `AbortSignal` in `completionStream(..., signal?)` which is passed through to the SDK call to cancel mid-stream.
- **Race condition fix**: To prevent interrupted conversations from being written to the wrong session log, each analysis records the `sessionId` at start (`requestSessionId`) and only writes to log if not aborted AND the session hasn't changed during analysis (`requestSessionId === currentSessionId`). This ensures interrupted conversations are not logged at all, rather than being written to the new session.

Conversation history (main-managed):

- The main process keeps a simple in-memory per-session string in `conversationHistoryBySession` formatted as:
  - `Q: <question>\nA: <answer>\n\n` appended per turn
- On each new request, main composes the prompt by prepending the sessionâ€™s initial prompt (if any) when regeneration provides an override history.
- On `Cmd/Ctrl+R` (clear) or `session:new`, main clears `conversationHistoryBySession` and `initialPromptBySession` and generates a new `sessionId`.

Logging (new):

- Module: `src/main/modules/log-manager.ts`
  - `writeConversationLog(sessionId: string, content: string): Promise<string>`
  - Writes plain-text conversation to `~/.ghost-ai/logs/<sessionId>/<sessionId>.log`.
- Integration point: in `capture:analyze-stream` handler, after appending `Q:`/`A:` to the sessionâ€™s history, call `await logManager.writeConversationLog(requestSessionId, conversationHistoryBySession.get(requestSessionId) ?? '')`.

HUD / Hide integration:

- `ipcMain.handle('hud:toggle-hide')` toggles visibility via `toggleHidden(mainWindow)`.
- When re-showing, main sends `hud:show` so the renderer can set `visible=true` and re-enable input.
- Rendererâ€™s Hide button calls `window.ghostAI.toggleHide()` instead of only local `visible=false`.

Ensure to unsubscribe listeners on `done` or `error` from the preload wrapper.

### Realtime Transcription

- Main module: `src/main/modules/realtime-transcribe.ts`
  - Opens `wss://api.openai.com/v1/realtime?intent=transcription`
  - Sends `transcription_session.update` with `input_audio_format: "pcm16"`, `turn_detection: { type: "server_vad", threshold: 0.5, silence_duration_ms: 350, prefix_padding_ms: 150 }`, and `input_audio_transcription.model: "gpt-4o-mini-transcribe"`
  - Language hint: `input_audio_transcription.language` is set from user settings (`en` or `zh`), default `en`, to avoid garbled Chinese output
  - Accepts `input_audio_buffer.append` events with base64 PCM16 mono @ 24kHz
  - Emits to renderer:
    - `transcribe:start`, `transcribe:delta` (streaming deltas), `transcribe:done` (sentence completed), `transcribe:error`, `transcribe:closed`
  - IPC channels: `transcribe:start` (handle), `transcribe:append`, `transcribe:end`, `transcribe:stop`
  - Logs: WS connect/open/close/error, message type hints, appended bytes per chunk, input buffer end

- Renderer (`src/renderer/main.tsx`):
  - Captures microphone via `getUserMedia({ audio: { echoCancellation:false, noiseSuppression:false, autoGainControl:false } })`
  - Attempts to capture system audio via `getDisplayMedia({ audio:true })` and discards video tracks
  - Mixes sources in `AudioContext`, downsamples to 24 kHz mono, converts to 16â€‘bit PCM, and performs client-side batching: flush every ~220 ms or at ~32 KB of PCM16 bytes. This reduces WS overhead and improves transcription stability with minimal latency.
  - Sends batches via `appendTranscriptionAudio` and renders transcript deltas via the same unified render sink used by analyze streaming: `appendLive(delta)` and `finalizeLive({ content })`
  - On each transcription completion, the renderer appends a pair into its local `history`: `{ role: 'user', content: <transcript> }` and `{ role: 'assistant', content: <transcript> }`, making each transcript segment a paginated page. You can Regenerate on such a page to analyze that transcript; the assistant content for that page is replaced in place while the user transcript is preserved.
  - Pause/Resume support: renderer gates both the elapsed timer and audio processing/delta application when paused (no IPC changes required)
  - On stop: sends `endTranscription` and `stopTranscription`, closes audio graph, stops tracks, and clears timers
  - Logs: microphone/system audio permission results and audio processing errors

## Renderer Flow (Ask UI)

- Component: `src/renderer/main.tsx` maintains `text`, `result`, `busy`, `streaming` states.
  - On Enter key: calls `ghostAI.analyzeCurrentScreenStream(...)`.
  - Appends deltas to `result` in real time.
  - Streamed content is rendered as Markdown using a read-only BlockNote editor. The renderer derives a `displayMarkdown` value showing either the live streamed content or the selected historical page. Historical pages include both assistant answers and transcript pages (transcripts are inserted as `{user, assistant}` where assistant initially mirrors the transcript). On each `displayMarkdown` change, the renderer converts Markdown with `editor.tryParseMarkdownToBlocks(displayMarkdown)` and replaces content via `editor.replaceBlocks(editor.document, blocks)`.
  - Code blocks are rendered without syntax highlighting. We removed the Shiki-based highlighter to simplify dependencies.
  - Shows the streamed response bubble ABOVE the input field.
  - Disables the input while streaming.
  - No non-streaming fallback; errors are surfaced inline and user can retry immediately.
  - Error handling: when an error occurs (from streaming or fallback), the UI writes an inline message to the same bubble in the form `Error: <message>` and re-enables input so the user can retry immediately.
  - Clear conversation: `Cmd/Ctrl+R` clears renderer `history` + `result` and also clears main-process conversation context.
  - Renderer `history` is for UI navigation only; model memory/context is managed in main.
  - Regeneration flow: after an answer finishes, the Ask footer shows a `â†» Regenerate` button. Clicking it:
    - Identifies the page to regenerate (current page if paged; otherwise the latest completed page)
    - Extracts that page's original user message from `history`
    - Builds a plain-text `Q:`/`A:` history string from all pairs before that page
    - Calls `analyzeCurrentScreenStream(userMessage, customPrompt, handlers, priorPlain)` where `priorPlain` is the string above
    - On completion, replaces the assistant content for that page in-place (does not append a new page)
  - Ask input placeholder: shows `Thinkingâ€¦` while busy/streaming; otherwise `Type your questionâ€¦`.

### Overlay click-through policy

- The main window is a full-screen, transparent overlay (no frame, no shadow) positioned over the primary display.
- By default it is click-through: `setIgnoreMouseEvents(true, { forward: true })` is enabled so underlying apps remain interactive.
- The renderer toggles click-through dynamically via `window.ghostAI.setMouseIgnore(false/true)` when the pointer is over the HUD bar or bubbles, and during drag.
- The root container uses `pointer-events: none` while interactive elements use `pointer-events: auto`, ensuring only visible UI captures input. This also allows dragging the HUD to the very top/bottom edges without invisible blockers.

### Validation messages

- When testing API settings via the "Test" button in Settings, the validation result is shown as a styled notification next to the button.
- Validation uses IconCheckCircle and IconXCircle from Icons.tsx to display success/failure states with appropriate colors.
- The notification appears in a styled container with a background color, border, and icon to improve visibility and user experience.
- The validation message style is defined inline in Settings.tsx in the JSX return section.

## UI Theming and Styles

- Centralized theme and styles live under `src/styles/`.
  - `theme.ts`: exports `theme` and `makeTheme(opacity?: number)`; the single `opacity` value synchronizes text/background transparency across the UI.
    - Change default opacity at the export site: `export const theme = makeTheme(0.85)`.
    - Edit base colors in `palette` (RGB tuples) to adjust text/background/primary/danger etc.
  - `styles.ts`: component styles (bar, settings card, ask card, buttons) consume `theme.color.*()` so most customization is done via `theme.ts`.
  - Prefer per-component tweaks via multipliers (e.g., `theme.color.panelBg(0.9)`) rather than hard-coded rgba.
  - Markdown viewer encapsulated in `src/components/MarkdownViewer.tsx`.
    - Assets are imported in `src/main.tsx` (global CSS imports).
    - Use `<MarkdownViewer markdown={displayMarkdown} />` to render.
  - Scrollbar styling for the AI answer panel lives in `src/styles/blocknote-custom.css` under `.bn-markdown-viewer` with both WebKit (::-webkit-scrollbar) and Firefox (scrollbar-width/color) rules to match the dark panel aesthetics.

## Screenshot Capture

- Captured via `screenshot-desktop` with PNG buffers.
- Uses `hideAllWindowsDuring(...)` to avoid self-capture.
- Main checks `loadUserSettings().attachScreenshot` before capturing. If false, capture is skipped and `openAIClient.responseStream(undefined, ...)` is called.

## Settings

- Persisted with `electron-store` and `safeStorage` (encrypts the OpenAI config blob).
- `Settings.tsx` reads and updates config via `window.ghostAI`.
- New: `settings:get`/`settings:update` now persist user preferences, including `transcribeLanguage: 'en' | 'zh'` (default `'en'`) and `attachScreenshot?: boolean` (default `true`). The latter controls whether each Ask includes a screenshot. When disabled, the main process skips capture and only sends the text question; `responseStream` accepts an optional `imageBuffer`.

## Coding Guidelines

- Keep all UI logic in renderer, system/IO in main.
- Prefer strong typing but be pragmatic with SDK surface changes.
- On streaming, always clean up listeners to avoid leaks.
- When modifying IPC channels, update:
  - `src/main/main.ts`
  - `src/main/preload.ts`
  - `src/global.d.ts`
  - This document.

# Ghost AI â€” Copilot Instructions (éœ€æ±‚èˆ‡è¨ˆç•«æ•´åˆ)

æœ¬æ–‡ä»¶æ•´åˆ `.kiro/specs/ghost-ai` ä¸­çš„éœ€æ±‚èˆ‡å¯¦ä½œè¨ˆç•«ï¼Œä½œç‚º Copilot èˆ‡å”ä½œé–‹ç™¼çš„å·¥ä½œæŒ‡å—ã€‚å°ˆæ¡ˆç‚ºç´” Electron + TypeScript è·¨å¹³å°æ¡Œé¢æ‡‰ç”¨ï¼Œç›´æ¥æ•´åˆ OpenAI APIï¼Œæ ¸å¿ƒèƒ½åŠ›åŒ…å«ï¼š

- æ–‡å­—è¼¸å…¥ + è¢å¹•æˆªåœ–åˆ†æ
- èªéŸ³éŒ„éŸ³ï¼ˆä¸¦é ç•™ WebRTC å¯¦æ™‚å°è©±ï¼‰
- éš±è—å¼æ“ä½œç•Œé¢èˆ‡å…¨åŸŸç†±éµ

**é‡è¦ï¼šæœ¬å°ˆæ¡ˆæ¡ç”¨ç´”å‰ç«¯ TypeScript + Electron æ¶æ§‹ï¼Œå®Œå…¨ç„¡å¾Œç«¯æœå‹™ã€‚æ‰€æœ‰åŠŸèƒ½éƒ½åœ¨ Electron æ‡‰ç”¨ç¨‹å¼å…§å¯¦ç¾ï¼ŒåŒ…æ‹¬ OpenAI API è¨­å®šéƒ½å¯åœ¨å‰ç«¯ç•Œé¢ä¸­é…ç½®ã€‚**

æ›´æ–°æ™‚è«‹èˆ‡ `.kiro/specs/ghost-ai/{requirements.md,tasks.md,design.md}` ä¿æŒä¸€è‡´ã€‚

---

## ä¸€ã€åŠŸèƒ½éœ€æ±‚èˆ‡é©—æ”¶æ¨™æº–ï¼ˆFunctional Requirementsï¼‰

ä»¥ä¸‹åŒ¯ç¸½è‡ª `requirements.md`ï¼Œä¿ç•™ User Story èˆ‡ Acceptance Criteriaï¼Œä½œç‚º DoDï¼ˆDefinition of Doneï¼‰çš„ä¾æ“šã€‚

### R1ï¼šæ–‡å­—è¼¸å…¥èˆ‡è¢å¹•æˆªåœ–åˆ†æ

- User Storyï¼šä½œç‚ºç”¨æˆ¶ï¼Œæˆ‘å¸Œæœ›é€éç†±éµå¿«é€Ÿå‘¼å«è¼¸å…¥æ¡†ï¼Œè¼¸å…¥å•é¡Œä¸¦è‡ªå‹•æˆªåœ–ï¼Œè®“ AI åŠ©æ‰‹åˆ†æç•¶å‰è¢å¹•å…§å®¹ä¸¦å›ç­”ã€‚
- Acceptance Criteriaï¼š
  1. ç•¶ç”¨æˆ¶æŒ‰ä¸‹è¨­å®šç†±éµï¼Œç³»çµ±æœƒç«‹å³é¡¯ç¤ºæ–‡å­—è¼¸å…¥æ¡†ã€‚
  2. ç•¶ç”¨æˆ¶é€å‡ºæ–‡å­—ï¼Œç³»çµ±æœƒè‡ªå‹•é€²è¡Œè¢å¹•æˆªåœ–ã€‚
  3. æˆªåœ–å®Œæˆå¾Œï¼Œå°‡ç”¨æˆ¶å•é¡Œã€è¢å¹•æˆªåœ–èˆ‡è‡ªå®šç¾©æç¤ºè©ä¸€ä½µé€è‡³ Chat Completion APIã€‚
  4. æˆªåœ–å¤±æ•—æ™‚ï¼Œé¡¯ç¤ºéŒ¯èª¤ä¸¦å…è¨±é‡è©¦ã€‚
  5. API å›æ‡‰å¾Œï¼Œåœ¨é©ç•¶ç•Œé¢é¡¯ç¤º AI å›ç­”ã€‚

### R2ï¼šèªéŸ³éŒ„éŸ³èˆ‡å¯¦æ™‚å°è©±ï¼ˆé ç•™ï¼‰

- User Storyï¼šä½œç‚ºç”¨æˆ¶ï¼Œæˆ‘å¸Œæœ›é€éæŒ‰éˆ•æˆ–ç†±éµé–‹å§‹éŒ„éŸ³ï¼Œä¸¦é ç•™æœªä¾† WebRTC å¯¦æ™‚å°è©±èƒ½åŠ›ã€‚
- Acceptance Criteriaï¼š
  1. æŒ‰ä¸‹éŒ„éŸ³æŒ‰éˆ•æˆ–ç†±éµï¼Œç«‹å³é–‹å§‹éŒ„éŸ³ã€‚
  2. éŒ„éŸ³ä¸­æœ‰æ˜ç¢ºç‹€æ…‹æŒ‡ç¤ºã€‚
  3. å†æ¬¡æŒ‰ä¸‹æ™‚åœæ­¢éŒ„éŸ³ä¸¦ä¿å­˜éŸ³è¨Šã€‚
  4. éº¥å…‹é¢¨æ¬Šé™è¢«æ‹’æ™‚ï¼Œé¡¯ç¤ºæ¬Šé™è«‹æ±‚æŒ‡å¼•ã€‚
  5. éŒ„éŸ³å®Œæˆå¾Œï¼Œé ç•™ WebRTC å¯¦æ™‚å°è©±ä»‹é¢ã€‚
  6. é¦–æ¬¡ä½¿ç”¨æ™‚ï¼Œæä¾›è¨­å®šç•Œé¢è®“ç”¨æˆ¶è¼¸å…¥OpenAI APIé‡‘é‘°å’ŒåŸºç¤URLã€‚

### R3ï¼šéš±è—å¼æ“ä½œç•Œé¢

- User Storyï¼šä½œç‚ºç”¨æˆ¶ï¼Œæˆ‘å¸Œæœ›å¯éš±è—æ“ä½œç•Œé¢ï¼Œé¿å…åœ¨è¢å¹•åˆ†äº«æˆ–æˆªåœ–æ™‚è¢«çœ‹åˆ°ã€‚
- Acceptance Criteriaï¼š
  1. æŒ‰ä¸‹éš±è—ç†±éµï¼Œç«‹å³éš±è—æ‰€æœ‰å¯è¦‹ç•Œé¢ã€‚
  2. éš±è—ç‹€æ…‹ä¸‹ï¼Œä¸å‡ºç¾åœ¨è¢å¹•æˆªåœ–æˆ–åˆ†äº«ä¸­ã€‚
  3. å†æ¬¡æŒ‰ä¸‹ç†±éµå¯æ¢å¾©é¡¯ç¤ºã€‚
  4. ç³»çµ±é‡å•Ÿå¾Œè¨˜ä½ä¸Šæ¬¡éš±è—ç‹€æ…‹ã€‚
  5. éš±è—ç‹€æ…‹ä¸‹ï¼Œå…¨åŸŸç†±éµä»å¯é‹ä½œã€‚

### R4ï¼šå…¨åŸŸç†±éµç³»çµ±

- User Storyï¼šä½œç‚ºç”¨æˆ¶ï¼Œæˆ‘å¸Œæœ›èƒ½è‡ªå®šç¾©æ‰€æœ‰åŠŸèƒ½ç†±éµï¼Œä¸¦åœ¨ä»»ä½•æ‡‰ç”¨ä¸­å¯ç”¨ã€‚
- Acceptance Criteriaï¼š
  1. è¨­å®šç†±éµæ™‚æª¢æŸ¥è¡çªä¸¦è­¦å‘Šã€‚
  2. ä»»ä½•æ‡‰ç”¨ä¸­æŒ‰ä¸‹ç†±éµï¼Œèƒ½æ­£ç¢ºè§¸ç™¼åŠŸèƒ½ã€‚
  3. ç³»çµ±å•Ÿå‹•æ™‚è‡ªå‹•è¨»å†Šæ‰€æœ‰ç†±éµã€‚
  4. è¨»å†Šå¤±æ•—æ™‚é€šçŸ¥ç”¨æˆ¶ä¸¦æä¾›æ›¿ä»£æ–¹æ¡ˆã€‚
  5. ä¿®æ”¹è¨­å®šå¾Œï¼Œç«‹å³æ›´æ–°è¨»å†Šã€‚

### R5ï¼šè‡ªå®šç¾©æç¤ºè©èˆ‡APIè¨­å®šç®¡ç†

- User Storyï¼šä½œç‚ºç”¨æˆ¶ï¼Œæˆ‘å¸Œæœ›èƒ½è¨­å®šèˆ‡ç®¡ç†è‡ªå®šç¾© AI æç¤ºè©ï¼Œä»¥åŠé…ç½®OpenAI APIé€£æ¥è¨­å®šã€‚
- Acceptance Criteriaï¼š
  1. æä¾›ç°¡æ½”çš„æç¤ºè©ç·¨è¼¯ä»‹é¢ã€‚
  2. ä¿å­˜æ™‚é©—è­‰æ ¼å¼ä¸¦å„²å­˜è‡³æœ¬åœ°ã€‚
  3. ç™¼é€è«‹æ±‚æ™‚è‡ªå‹•åŒ…å«è‡ªå®šç¾©æç¤ºè©ã€‚
  4. éé•·æ™‚çµ¦å‡ºè­¦å‘Šèˆ‡å„ªåŒ–å»ºè­°ã€‚
  5. é‡ç½®æ™‚æ¢å¾©é è¨­æ¨¡æ¿ã€‚
  6. é–‹å•Ÿè¨­å®šæ™‚æä¾›APIé‡‘é‘°ã€åŸºç¤URLã€æ¨¡å‹é¸æ“‡ç­‰é…ç½®é¸é …ã€‚
  7. ä¿å­˜APIè¨­å®šæ™‚åŠ å¯†å„²å­˜æ•æ„Ÿè³‡è¨Šä¸¦é©—è­‰é€£æ¥æœ‰æ•ˆæ€§ã€‚

### R6ï¼šAI åˆ†æèˆ‡å›æ‡‰è™•ç†

- User Storyï¼šä½œç‚ºç”¨æˆ¶ï¼Œæˆ‘å¸Œæœ› AI èƒ½æº–ç¢ºåˆ†æè¼¸å…¥èˆ‡è¢å¹•å…§å®¹ï¼Œæä¾›æœ‰ç”¨å›æ‡‰ã€‚
- Acceptance Criteriaï¼š
  1. æ”¶åˆ°æˆªåœ–èˆ‡æç¤ºè©å¾Œï¼Œä½¿ç”¨å‰ç«¯è¨­å®šçš„APIé‡‘é‘°ç›´æ¥é€é OpenAI API è™•ç†åœ–ç‰‡åˆ†æã€‚
  2. å›å‚³åˆ†æçµæœå¾Œï¼Œåœ¨ç•Œé¢é¡¯ç¤ºã€‚
  3. API å¤±æ•—æ™‚é¡¯ç¤ºéŒ¯èª¤ä¸¦å¯é‡è©¦ã€‚
  4. åˆ†æå®Œæˆå¾Œï¼Œæ”¯æ´è¤‡è£½çµæœæˆ–é€²è¡Œå¾ŒçºŒæ“ä½œã€‚
  5. è™•ç†éŸ³è¨Šæ™‚ï¼Œæ”¯æ´èªéŸ³è½‰æ–‡å­—ä¸¦æ•´åˆåˆ†ææµç¨‹ã€‚

### R7ï¼šç³»çµ±æ•´åˆèˆ‡ç©©å®šæ€§

- User Storyï¼šä½œç‚ºç”¨æˆ¶ï¼Œæˆ‘å¸Œæœ›ç³»çµ±ç©©å®šé‹è¡Œä¸¦èˆ‡ä½œæ¥­ç³»çµ±è‰¯å¥½æ•´åˆã€‚
- Acceptance Criteriaï¼š
  1. å•Ÿå‹•å¾Œåœ¨ç³»çµ±æ‰˜ç›¤é¡¯ç¤ºåœ–ç¤ºä¸¦æä¾›åŸºæœ¬æ§åˆ¶ã€‚
  2. ç™¼ç”ŸéŒ¯èª¤æ™‚è¨˜éŒ„æ—¥èªŒä¸¦å˜—è©¦è‡ªå‹•æ¢å¾©ã€‚
  3. ç™»å‡ºæˆ–é—œæ©Ÿæ™‚æ­£ç¢ºæ¸…ç†è³‡æºèˆ‡ä¿å­˜è¨­å®šã€‚
  4. å´©æ½°å¾Œé‡å•Ÿå¯æ¢å¾©åˆ°ä¸Šæ¬¡å·¥ä½œç‹€æ…‹ã€‚
  5. ç³»çµ±æ›´æ–°å¾Œä¿ç•™ç”¨æˆ¶è‡ªå®šç¾©è¨­å®šã€‚
  6. æ‡‰ç”¨ç¨‹å¼å¯æ‰“åŒ…åˆ° Windows/macOS/Linuxã€‚

### R8ï¼šéš±ç§ä¿è­·èˆ‡å®‰å…¨æ€§

- User Storyï¼šä½œç‚ºç”¨æˆ¶ï¼Œæˆ‘å¸Œæœ›æˆ‘çš„è³‡æ–™è¢«å¦¥å–„ä¿è­·ï¼Œç³»çµ±é‹è¡Œä¸è¢«ä»–äººè¼•æ˜“åµæ¸¬ã€‚
- Acceptance Criteriaï¼š
  1. é‹è¡Œæ™‚æ¡ç”¨éš±è”½çš„ç¨‹åºåç¨±èˆ‡è¦–çª—æ¨™é¡Œã€‚
  2. æˆªåœ–èˆ‡éŸ³è¨Šåƒ…åœ¨è¨˜æ†¶é«”ä¸­è™•ç†ï¼Œä¸è½åœ°ã€‚
  3. èˆ‡ API é€šè¨Šæ¡ç”¨åŠ å¯†é€£ç·šä¸¦æ¸…ç†ç¶²è·¯æ—¥èªŒã€‚
  4. åµæ¸¬åˆ°ç›£æ§è»Ÿé«”æ™‚è­¦å‘Šç”¨æˆ¶æ½›åœ¨é¢¨éšªã€‚
  5. é—œé–‰æ‡‰ç”¨æ™‚æ¸…ç†æ‰€æœ‰æš«å­˜èˆ‡è¨˜æ†¶é«”ç—•è·¡ã€‚
  6. å„²å­˜APIé‡‘é‘°æ™‚ä½¿ç”¨æœ¬åœ°åŠ å¯†å„²å­˜ï¼Œä¸ä¾è³´å¤–éƒ¨æœå‹™ã€‚
  7. è¨­å®šæ•æ„Ÿè³‡è¨Šæ™‚æä¾›å®‰å…¨æ€§è­¦å‘Šå’Œæœ€ä½³å¯¦è¸å»ºè­°ã€‚

---

## äºŒã€éåŠŸèƒ½æ€§éœ€æ±‚ï¼ˆNFRï¼Œç¯€é¸è‡ªè¨­è¨ˆï¼‰

å‡ºè‡ª `design.md` çš„ç´„æŸï¼ˆè«‹æ“šæ­¤å¯¦ä½œèˆ‡æª¢æŸ¥ï¼‰ï¼š

- éŒ¯èª¤è™•ç†ç­–ç•¥ï¼š
  - ç†±éµè¨»å†Šå¤±æ•—ï¼šæ›¿ä»£çµ„åˆã€ç”¨æˆ¶æç¤ºã€ä¸ä¸­æ–·é‹è¡Œ
  - æˆªåœ–å¤±æ•—ï¼šæœ€å¤š 3 æ¬¡é‡è©¦ã€é™ç´šè‡³è¦–çª—æˆªåœ–ã€å‹å–„éŒ¯èª¤
  - ç¶²è·¯é€£ç·šï¼šè‡ªå‹•é‡è©¦ã€é›¢ç·šæç¤ºã€è«‹æ±‚å¿«å–
  - OpenAI APIï¼šæŒ‡æ•¸é€€é¿ã€é…é¡/ç”¨é‡ç›£æ§ã€å¿…è¦æ™‚é™ç´š
  - è·¨å¹³å°éŒ¯èª¤ï¼šå¹³å°ç‰¹å®šé™ç´šã€å¯ç”¨æ€§æª¢æ¸¬ã€å°æ‡‰è¨Šæ¯
  - è³‡æºä¸è¶³ï¼šè¨˜æ†¶é«”ç›£æ§/æ¸…ç†ã€å„ªé›…é™ç´šã€è­¦å‘Š

- éš±ç§èˆ‡å®‰å…¨ï¼š
  - åƒ…åœ¨è¨˜æ†¶é«”ä¸­è™•ç†åœ–ç‰‡èˆ‡éŸ³è¨Šï¼Œå®‰å…¨æ¸…ç†ç·©è¡å€
  - HTTPSã€å¯è€ƒæ…®æ†‘è­‰å›ºå®šèˆ‡è«‹æ±‚æ¨™é ­æ··æ·†
  - ç¨‹åºéš±è”½ï¼ˆéš¨æ©Ÿåç¨±ã€éš±è—æ¨™é¡Œã€æœ€å°è¶³è·¡ï¼‰
  - æš«å­˜è³‡æ–™è‡ªå‹•æ¸…ç†èˆ‡åŠ å¯†ï¼›API é‡‘é‘°ä»¥ç’°å¢ƒè®Šæ•¸é…ç½®ä¸¦é™åˆ¶å­˜å–

- æ•ˆèƒ½æœ€ä½³åŒ–ï¼š
  - å•Ÿå‹•æœ€ä½³åŒ–ï¼ˆå»¶é²è¼‰å…¥ã€é è¼‰è³‡æºã€èƒŒæ™¯åˆå§‹åŒ–ã€åˆ†éšæ®µå•Ÿå‹•ï¼‰
  - è¨˜æ†¶é«”æœ€ä½³åŒ–ï¼ˆåŠæ™‚é‡‹æ”¾ã€ç”Ÿå‘½é€±æœŸç®¡ç†ã€GC æœ€ä½³åŒ–ã€ç›£æ§ï¼‰
  - è·¨å¹³å°æœ€ä½³åŒ–èˆ‡åŸç”Ÿ API åˆ©ç”¨
  - API é€šè¨Šæœ€ä½³åŒ–ï¼ˆé€£ç·šæ± ã€å¿«å–ã€å£“ç¸®ã€æ‰¹æ¬¡è™•ç†ï¼‰

---

## ä¸‰ã€å¯¦ä½œè¨ˆç•«ï¼ˆImplementation Planï¼‰

ä»¥ä¸‹æ•´åˆè‡ª `tasks.md`ï¼Œç‚ºé–‹ç™¼å„ªå…ˆåºèˆ‡å·¥ä½œæ‹†è§£ï¼Œå«è·¯å¾‘ç´„å®šèˆ‡éœ€æ±‚å°æ‡‰ï¼š

- [ ] 1. å°ˆæ¡ˆéª¨æ¶èˆ‡æ ¸å¿ƒä»‹é¢
  - å»ºç«‹ç›®éŒ„ï¼š`src/main/`, `src/renderer/`, `src/shared/`, `src/services/`
  - å®šç¾©ä¸‰å¤§åŠŸèƒ½çš„ TS ä»‹é¢ï¼›è¨­å®š `package.json`/`tsconfig.json`
  - å®‰è£ OpenAI SDK èˆ‡å¿…è¦å¥—ä»¶ï¼ˆelectron, typescript, react, electron-builderâ€¦ï¼‰
  - ä»¥ UI è¨­å®šæ–¹å¼ç®¡ç† `OPENAI_BASE_URL`, `OPENAI_API_KEY`ï¼ˆä¸å¼·åˆ¶ä½¿ç”¨ç’°å¢ƒè®Šæ•¸ï¼‰
  - æ‰“åŒ…è¨­å®šï¼ˆWin/macOS/Linuxï¼‰
  - å°æ‡‰éœ€æ±‚ï¼šR1, R2, R3, R4, R7.6

### UI æŒ‡å—ï¼ˆRenderer ç«¯ï¼‰

- æ–°çš„ UI æ¡ç”¨ã€Œé ‚éƒ¨ç½®ä¸­æ§åˆ¶åˆ—ï¼ˆHUDï¼‰ç‚ºä¸»ï¼Œé¢æ¿æŒ‰éœ€é¡¯ç¤ºã€è¨­è¨ˆï¼š
  - æ‡‰ç”¨å•Ÿå‹•å¾Œé è¨­ç‚ºéš±è—ï¼ˆ`visible=false`ï¼‰ï¼Œä¸é¡¯ç¤ºä»»ä½•é¢æ¿ã€‚
  - é€éç†±éµæˆ–æ‰˜ç›¤é¸å–®è§¸ç™¼ `text-input:show` æ™‚ï¼Œåƒ…é¡¯ç¤ºé ‚éƒ¨ HUDï¼›æ­¤æ™‚ä¸è‡ªå‹•æ‰“é–‹ä»»ä½•æ³¡æ³¡æˆ–è¨­å®šé¢æ¿ï¼ˆé¿å…ç•«é¢é›œè¨Šï¼‰ã€‚
  - HUD åŒ…å« `Listen`ã€`Ask`ã€`Hide`ã€`Settings` å››å€‹æŒ‰éˆ•ï¼›`Ask`/`Settings` çš†ç‚ºã€Œåˆ‡æ›é¡¯ç¤º/éš±è—ã€çš„è¡Œç‚ºï¼ˆå†æ¬¡é»æ“Šå¯æ”¶åˆï¼‰ã€‚
  - éŒ„éŸ³ä¸­æŒ‰éˆ•æœƒåˆ‡æ›æˆç´…è‰²ä¸¦é¡¯ç¤º `mm:ss` è¨ˆæ™‚ã€‚
  - éœ€è¦è¼¸å…¥å•é¡Œæˆ–æŸ¥çœ‹è¨­å®šæ™‚ï¼Œæ‰åœ¨ HUD ä¸‹æ–¹é¡¯ç¤ºå°è©±æ³¡æ³¡/è¨­å®šå¡ç‰‡ã€‚
  - æ¨£å¼ä½¿ç”¨å…§è¯æ¨£å¼ï¼Œæ·±è‰²ç»ç’ƒè³ªæ„Ÿï¼ˆåŠé€æ˜æ·±è‰²èƒŒæ™¯ + é‚Šæ¡† + é™°å½±ï¼‰ã€‚
  - ä¸»è¦æª”æ¡ˆï¼š`src/renderer/main.tsx`ã€`src/renderer/components/Settings.tsx`ã€`src/renderer/components/Icons.tsx`ã€‚

- é‡è¦äº’å‹•æµç¨‹ï¼š
  - `window.ghostAI.onTextInputShow` é¡¯ç¤º HUD ä¸¦ç›´æ¥æ‰“é–‹ `Ask`ï¼Œç„¦é»ç§»åˆ°å–®è¡Œè¼¸å…¥ã€‚
  - `Ask` åªæœ‰å–®è¡Œè¼¸å…¥æ¡†ï¼›Enter é€å‡ºï¼ˆIME çµ„å­—æ™‚ä¸é€å‡ºï¼‰ã€‚
  - `Settings` é¢æ¿æ²¿ç”¨ IPCï¼š`openai:update-config`ã€`openai:get-config`ã€`openai:validate-config`ï¼Œä¸¦æ–°å¢ `settings:get`ã€`settings:update` ç®¡ç†ä½¿ç”¨è€…åå¥½ï¼ˆä¾‹å¦‚é è¨­ custom promptï¼‰ã€‚

- å‹åˆ¥è£œå……ï¼šåœ¨ `tsconfig.json` åŠ å…¥ `"types": ["vite/client"]` ä»¥æ”¯æ´ `import.meta.env`ã€‚

### è¦–çª—èˆ‡éš±å½¢å±¬æ€§ï¼ˆMain ç«¯ï¼‰

- `BrowserWindow` æ¡ç”¨çµ•å°éš±å½¢è¦†è“‹å±¤è¨­å®šï¼Œé¿å…å‡ºç¾é¡ä¼¼ Chrome çš„æ¨™æº–è¦–çª—ï¼š
  - `show: false`ï¼ˆå•Ÿå‹•ä¸é¡¯ç¤ºï¼‰
  - `frame: false`
  - `transparent: true`
  - `backgroundColor: '#00000000'`
  - `resizable: false`, `fullscreenable: false`, `hasShadow: false`, `skipTaskbar: true`, `alwaysOnTop: true`
  - é—œé–‰é¸å–®åˆ—ï¼š`mainWindow.setMenuBarVisibility(false)`
- åªæœ‰åœ¨ä½¿ç”¨è€…é€éç†±éµæˆ–æ‰˜ç›¤æ“ä½œæ™‚æ‰ `mainWindow.show()`ï¼Œä¸¦ç”± Renderer ç«¯æ§åˆ¶ HUD/é¢æ¿çš„é¡¯ç¤ºã€‚
- æˆªåœ–æµç¨‹é€é `hideAllWindowsDuring` æš«æ™‚éš±è—æ‰€æœ‰è¦–çª—ï¼Œé¿å…å¹²æ“¾æˆªåœ–èˆ‡ç•™ä¸‹é›œè¨Šã€‚

### ç†±éµï¼ˆå›ºå®šï¼Œå…¨éƒ¨å…¨å±€ï¼‰

-- æ‰€æœ‰ç†±éµå‡æ¡ç”¨ Main ç«¯ `globalShortcut` è¨»å†Šï¼ŒRenderer ä¸å†è‡ªè¡Œè™•ç†éµç›¤äº‹ä»¶ï¼š

- `Cmd/Ctrl+Enter`ï¼šé¡¯ç¤º HUD ä¸¦æ‰“é–‹ Askï¼ˆä¸”è‡ªå‹•èšç„¦ï¼‰
- `Cmd/Ctrl+Shift+Enter`ï¼šåˆ‡æ›èªéŸ³éŒ„éŸ³ï¼ˆé–‹å§‹/åœæ­¢ï¼‰ã€‚ç›®å‰åƒ…åˆ‡æ› UI èˆ‡éŒ„éŸ³è¨ˆæ™‚ï¼Œä¸é€²è¡Œè½‰éŒ„ã€‚
- `Cmd/Ctrl+\\`ï¼šéš±è—/é¡¯ç¤º HUDï¼ˆåˆ‡æ›ï¼‰
- `Cmd/Ctrl+R`ï¼šæ¸…é™¤ Ask å°è©±èˆ‡çµæœï¼Œä¸¦é‡ç½®èªéŸ³ç‹€æ…‹ï¼ˆåœæ­¢éŒ„éŸ³ä¸¦ä¸Ÿæ£„æš«å­˜éŸ³è¨Šï¼‰

### æœƒè©±ï¼ˆTop-level Sessionï¼‰

- æ‡‰ç”¨ç¨‹å¼åœ¨å•Ÿå‹•æ™‚æœƒç”Ÿæˆä¸€å€‹é ‚å±¤ `sessionId`ï¼ˆUUIDï¼‰ã€‚
- è§¸ç™¼ `Cmd/Ctrl+R` æ¸…é™¤æ™‚ï¼Œä¸»ç¨‹åºæœƒï¼š
  - æ¸…ç©º `conversationHistoryText`
  - ç”Ÿæˆæ–°çš„ `sessionId`
  - å»£æ’­ `session:changed` çµ¦ Rendererï¼Œä¸¦å˜—è©¦åœæ­¢ç›®å‰çš„è½‰éŒ„é€£ç·š
- IPCï¼š
  - `session:get` â†’ `{ sessionId }`
  - `session:new` â†’ å»ºç«‹æ–° session ä¸¦å›å‚³ `{ sessionId }`
  - äº‹ä»¶ï¼š`session:changed` â†’ `{ sessionId }`
- æ‰€æœ‰æˆªåœ–åˆ†æä¸²æµäº‹ä»¶éƒ½æœƒæ”œå¸¶ `sessionId`ï¼ˆå¿…å¡«ï¼‰ï¼š
  - `capture:analyze-stream:start|delta|error`
  - `capture:analyze-stream:done` çš„ `AnalysisResult` äº¦æ”œå¸¶ `sessionId`
- å³æ™‚è½‰éŒ„äº‹ä»¶ä¹Ÿæœƒæ”œå¸¶ `sessionId`ï¼ˆå¿…å¡«ï¼‰ï¼š
  - `transcribe:start|delta|done|error`
- ç´€éŒ„æª”ï¼š`writeConversationLog(id, content)` ç›®å‰ä»¥ `sessionId` ç‚ºæª”åä¸¦å­˜æ”¾æ–¼è³‡æ–™å¤¾ `~/.ghost-ai/logs/<sessionId>/<sessionId>.log`ã€‚
  åŒæ™‚æœƒåœ¨æ¯æ¬¡æ›´æ–°æ™‚è¼¸å‡º `~/.ghost-ai/logs/<sessionId>/<sessionId>.json`ï¼ŒåŒ…å«ï¼š
  - `entries[]`: `{ index, requestId, log_path, text_input, ai_output }`
  - `nextIndex`: ä¸‹ä¸€å€‹ç´¢å¼•

### Session Store (global list-dict)

- æ¨¡çµ„ï¼š`src/main/modules/session-store.ts`
- åŠŸèƒ½ï¼šä»¥ `sessionId` ç‚º keyï¼Œç¶­è­·æ¯æ¬¡é€å‡ºï¼ˆAsk + åœ–ç‰‡ + å¯èƒ½çš„ Listen è½‰éŒ„å¿«ç…§ï¼‰çš„çµæ§‹åŒ–æ¸…å–®ã€‚
  - `appendEntry(sessionId, { requestId, text_input, ai_output })`: æ–°å¢ä¸€ç­† entryï¼Œä¸¦è‡ªå‹•è³¦äºˆæµæ°´è™Ÿ `index`
  - `updateSessionLogPath(sessionId, logPath)`: æ›´æ–°è©² session çš„ `log_path`
  - ä¸ç·©å­˜æˆ–è½åœ°ä»»ä½• Listen é€å­—ç¨¿ï¼›è½‰éŒ„å…§å®¹åƒ…ç”¨æ–¼å³æ™‚ UI é¡¯ç¤º
  - `getSessionsData()`: è¼¸å‡º `[{ sessionId: [entries...] }, ...]` å½¢æ…‹ä¾›é™¤éŒ¯
  - `toJSON()`: è¼¸å‡º `{ [sessionId]: { entries, nextIndex, log_path } }` å½¢æ…‹ï¼Œæä¾›æŒä¹…åŒ–ç”¨
- æ•´åˆé»ï¼š
  - å½±åƒåˆ†æå®Œæˆï¼ˆ`capture:analyze-stream:done`ï¼‰å¾Œï¼š
    1. å¯«å…¥ `~/.ghost-ai/logs/<sessionId>/<sessionId>.log`
    2. æ“·å–ä¸¦æ¸…ç©ºè½‰éŒ„å¿«ç…§ï¼Œ`appendEntry(...)`
    3. `updateSessionLogPath(...)`
    4. å°‡ `toJSON()[sessionId]` å¯«å…¥ `~/.ghost-ai/logs/<sessionId>/<sessionId>.json`
  - æ¸…é™¤ï¼ˆCtrl/Cmd+Rï¼‰æˆ– `session:new`ï¼šæ¸…æ‰ store ä¸¦é‡ç½® `sessionId`
- IPC/Preloadï¼š
  - `ipcMain.handle('session:dump')`ã€`window.ghostAI.dumpSession()` å¯å³æ™‚è®€å–ç•¶å‰ list-dict

ç¯„ä¾‹ï¼ˆ`session:dump` çš„è¼¸å‡ºå½¢æ…‹ï¼‰ï¼š

```
[
  {
    "d1a4c8c6-8f3c-4f8e-9fd0-2e7f5b6c5a12": [
      {
        "index": 0,
        "requestId": "f0a3e9f8-1c32-4e1b-9e7f-91a2b4c3d5e6",
        "log_path": "C:\\Users\\Wei\\.ghost-ai\\logs\\d1a4c8c6-8f3c-4f8e-9fd0-2e7f5b6c5a12\\d1a4c8c6-8f3c-4f8e-9fd0-2e7f5b6c5a12.log",
        "text_input": "ä½¿ç”¨è€…è¼¸å…¥çš„å…§å®¹ï¼ˆå¯ç‚ºç©ºï¼‰",
        "ai_output": "æ¨¡å‹çš„å›æ‡‰ï¼ˆå®Œæ•´å…§å®¹ï¼‰"
      }
    ]
  }
]
```

### å½±åƒåˆ†æä¸²æµï¼ˆç©ºç™½è¼¸å…¥è™•ç†èˆ‡æç¤ºè©è§’è‰²ï¼‰

- è‹¥ Renderer å‚³å…¥çš„ `textPrompt` ç‚ºç©ºå­—ä¸²ï¼Œä¸»ç¨‹åºä»æœƒé€å‡ºè«‹æ±‚ï¼›åœ¨ SDK å‘¼å«å‰ï¼Œæœƒä»¥é è¨­æ–‡å­— `'Please analyze this screenshot.'` é€²è¡Œè£œé½Šï¼Œç¢ºä¿ä¸²æµèƒ½æ­£å¸¸è¿”å›ã€‚
- å•Ÿç”¨ä¸­çš„è‡ªå®šç¾©æç¤ºè©ï¼ˆå¾ `prompts-manager` è®€å–ï¼‰æœƒä»¥ `system` è§’è‰²é™„åŠ ï¼Œæä¾›å…¨åŸŸæŒ‡ç¤ºï¼›é¿å…ä½¿ç”¨ `assistant` è§’è‰²ä»¥å…å½±éŸ¿æ¨¡å‹è¡Œç‚ºã€‚

â€“ `Cmd/Ctrl+Up`ï¼šå‘ä¸Šæ²å‹•å…§å®¹
â€“ `Cmd/Ctrl+Down`ï¼šå‘ä¸‹æ²å‹•å…§å®¹
â€“ `Cmd/Ctrl+Shift+Up`ï¼šåˆ‡æ›åˆ°ä¸Šä¸€é ï¼ˆä¸Šä¸€å‰‡åŠ©ç†å›ç­”ï¼‰
â€“ `Cmd/Ctrl+Shift+Down`ï¼šåˆ‡æ›åˆ°ä¸‹ä¸€é ï¼ˆä¸‹ä¸€å‰‡åŠ©ç†å›ç­”ï¼›åœ¨æœ€å¾Œä¸€é æ™‚è¿”å›åˆ°ã€Œæœ€æ–°/ç›´æ’­ã€è¦–åœ–ï¼‰

- æ›´æ–°ï¼šRenderer æ”¹ä»¥ `ask:paginate` äº‹ä»¶ï¼ˆç”± Preload æš´éœ² `window.ghostAI.onAskPaginate(handler)`ï¼‰è™•ç†åˆ†é åˆ‡æ›ï¼›`ask:scroll` æ¢å¾©ç‚ºå…§å®¹æ»¾å‹•ã€‚

### é¸å–®å¿«æ·éµï¼ˆé¿å…èˆ‡ Renderer æ¸…é™¤å¿«æ·éµè¡çªï¼‰

- `View` é¸å–®çš„ Reload æ”¹ç”¨ `F5` ä½œç‚ºåŠ é€Ÿéµï¼Œé¿å…è¦†è“‹å…¨å±€ `Cmd/Ctrl+R`ï¼ˆæ¸…é™¤ Ask å°è©±ï¼‰ã€‚

- [ ] 2. å…¨åŸŸç†±éµç³»çµ±
  - [ ] 2.1 `./src/main/hotkey-manager.ts`ï¼šè¨»å†Šæ–‡å­—/éŒ„éŸ³/éš±è—ç†±éµï¼Œè·¨å¹³å°èˆ‡è¡çªæª¢æ¸¬ï¼›å‹åˆ¥æ”¾ `./src/shared/types.ts`
    - å°æ‡‰ï¼šR4 å…¨éƒ¨æ¢ç›®
  - [ ] 2.2 ç†±éµè¨­å®šç®¡ç†ï¼šæœ¬åœ°å„²å­˜ã€è‡ªè¨‚ UIã€é©—è­‰ã€å‹•æ…‹æ›´æ–°ã€é è¨­èˆ‡é‡ç½®
    - å°æ‡‰ï¼šR4.1, R4.2, R4.4, R4.5

- [ ] 3. æ–‡å­—è¼¸å…¥èˆ‡è¢å¹•æˆªåœ–åˆ†æ
  - [ ] 3.1 `./src/renderer/components/TextInputComponent`ï¼šç†±éµè§¸ç™¼é¡¯ç¤ºã€è¼¸å…¥é©—è­‰èˆ‡é€å‡ºã€çµ±ä¸€æ¨£å¼
    - å°æ‡‰ï¼šR1.1â€“R1.3
  - [ ] 3.2 `./src/main/screenshot-manager.ts`ï¼šè·¨å¹³å°æˆªåœ–ã€è¨˜æ†¶é«”è™•ç†ã€é‡è©¦èˆ‡éŒ¯èª¤è™•ç†
    - å°æ‡‰ï¼šR1.2, R1.4
  - [ ] 3.3 æ•´åˆï¼šçµ„åˆç”¨æˆ¶å•é¡Œ/æˆªåœ–/è‡ªå®šç¾©æç¤ºè©ï¼Œæ ¼å¼åŒ– Chat Completion è«‹æ±‚ï¼Œé¡¯ç¤ºçµæœèˆ‡é‡è©¦
    - å°æ‡‰ï¼šR1.3, R1.5

- [ ] 4. èªéŸ³éŒ„éŸ³
  - [ ] 4.1 `./src/main/audio-manager.ts`ï¼šæ¬Šé™è«‹æ±‚ã€è¨­å‚™æª¢æ¸¬ã€é–‹å§‹/åœæ­¢ã€è¨˜æ†¶é«”è™•ç†èˆ‡æ ¼å¼è½‰æ›
    - å°æ‡‰ï¼šR2.1, R2.2, R2.4
  - [ ] 4.2 éŒ„éŸ³ç‹€æ…‹æŒ‡ç¤º UIï¼šæ™‚é•·èˆ‡éŸ³é‡æŒ‡ç¤ºã€é€šçŸ¥èˆ‡ç¢ºèª
    - å°æ‡‰ï¼šR2.2, R2.3
  - [ ] 4.3 WebRTC é ç•™ï¼šæ¶æ§‹èˆ‡ä»‹é¢ã€æ•¸æ“šæ¨¡å‹ã€éŸ³è¨Šæµè™•ç†åŸºç¤ã€è¨­å®šé¸é …
    - å°æ‡‰ï¼šR2.5

- [ ] 5. éš±è—å¼æ“ä½œç•Œé¢
  - [ ] 5.1 `./src/main/hide-manager.ts`ï¼šå®Œå…¨éš±è—/æ¢å¾©ã€æˆªåœ–/åˆ†äº«æ™‚éš±è—ã€ç‹€æ…‹æŒä¹…åŒ–
    - å°æ‡‰ï¼šR3.1, R3.2, R3.4
  - [ ] 5.2 éš±è—ç‹€æ…‹ç®¡ç†ï¼šè¨˜æ†¶èˆ‡æ¢å¾©ã€é‡å•Ÿæ¢å¾©ã€éš±è—æ¨¡å¼ä¸‹ç†±éµä¿æŒã€ç”¨æˆ¶é€šçŸ¥
    - å°æ‡‰ï¼šR3.3, R3.4, R3.5

- [ ] 6. è‡ªå®šç¾©æç¤ºè©èˆ‡APIè¨­å®šç®¡ç†
  - [ ] 6.1 æœ¬åœ°å„²å­˜èˆ‡ç®¡ç†ã€ç·¨è¼¯ UI èˆ‡é©—è­‰ã€æ¨¡æ¿èˆ‡é è¨­ã€åŒ¯å…¥åŒ¯å‡º
    - å°æ‡‰ï¼šR5.1, R5.2
  - [ ] 6.2 APIè¨­å®šç®¡ç†ç•Œé¢ï¼šOpenAI APIè¨­å®šçš„å‰ç«¯é…ç½®ã€é‡‘é‘°/URL/æ¨¡å‹è¨­å®šã€é©—è­‰èˆ‡æ¸¬è©¦ã€åŠ å¯†å„²å­˜ã€é¦–æ¬¡ä½¿ç”¨å¼•å°
    - å°æ‡‰ï¼šR5.6, R5.7, R6.6
  - [ ] 6.3 èˆ‡åˆ†ææµç¨‹æ•´åˆï¼šçµ„åˆé‚è¼¯ã€é•·åº¦é©—è­‰èˆ‡å„ªåŒ–å»ºè­°ã€é è¦½ã€å‹•æ…‹æ›¿æ›èˆ‡è®Šæ•¸
    - å°æ‡‰ï¼šR5.3, R5.4

- [ ] 7. OpenAI ç›´æ¥æ•´åˆ
  - [ ] 7.1 `./src/shared/openai-client.ts`ï¼šChat Completion å‘¼å«ã€å‰ç«¯å‹•æ…‹é…ç½®ã€é‡‘é‘°ç®¡ç†ã€å®‰å…¨èˆ‡é‡è©¦ã€æ¨¡å‹æ¸…å–®ç²å–
    - å°æ‡‰ï¼šR6.1, R6.2, R6.6, R8.3
  - [ ] 7.2 Vision åœ–ç‰‡åˆ†ææ•´åˆï¼šæ–‡å­—+åœ–ç‰‡ç¶œåˆåˆ†æã€base64/æ ¼å¼è™•ç†ã€çµæœæ ¼å¼åŒ–èˆ‡é¡¯ç¤ºï¼ˆMain Processï¼‰
    - å°æ‡‰ï¼šR6.1, R6.2, R6.4
  - [ ] 7.3 Whisper èªéŸ³è½‰æ–‡å­—ï¼šæ ¼å¼é©—è­‰èˆ‡è½‰æ›ã€base64 è™•ç†ã€çµæœé¡¯ç¤º
    - å°æ‡‰ï¼šR6.5

- [ ] 8. ç³»çµ±æ•´åˆèˆ‡ç©©å®šæ€§
  - [ ] 8.1 æ‰˜ç›¤èˆ‡ç‹€æ…‹ï¼šæ‰˜ç›¤åœ–ç¤º/æ§åˆ¶ã€ç‹€æ…‹ç›£æ§ã€å•Ÿå‹•åˆå§‹åŒ–ã€å„ªé›…é—œé–‰èˆ‡æ¸…ç†
    - å°æ‡‰ï¼šR7.1, R7.3, R7.5
  - [ ] 8.2 éŒ¯èª¤è™•ç†èˆ‡æ¢å¾©ï¼šå…¨åŸŸéŒ¯èª¤èˆ‡æ—¥èªŒã€å´©æ½°è‡ªå‹•æ¢å¾©ã€è¨­å®šå‚™ä»½/å¾©åŸã€éŒ¯èª¤å ±å‘Š
    - å°æ‡‰ï¼šR7.2, R7.4

- [ ] 9. éš±ç§ä¿è­·èˆ‡å®‰å…¨æ€§
  - [ ] 9.1 è¨˜æ†¶é«”å®‰å…¨ï¼šå®‰å…¨æ¸…ç†ã€åœ–ç‰‡/éŸ³è¨Šç·©è¡è‡ªå‹•æ¸…ç†ã€æ•æ„Ÿè³‡æ–™åŠ å¯†ã€é˜²æ­¢äº¤æ›è‡³è™›æ“¬è¨˜æ†¶é«”
    - å°æ‡‰ï¼šR8.2, R8.5
  - [ ] 9.2 ç¨‹åºéš±è”½èˆ‡éš±ç§æ¨¡å¼ï¼šéš¨æ©Ÿç¨‹åºåã€éš±è—è¦–çª—æ¨™é¡Œã€ç›£æ§è»Ÿé«”åµæ¸¬è­¦å‘Šã€æµé‡åŠ å¯†èˆ‡æ¨™é ­æ··æ·†ã€å®Œæ•´éš±ç§æ¨¡å¼
    - å°æ‡‰ï¼šR8.1, R8.3, R8.4, R8.5

- [ ] 10. æ¸¬è©¦èˆ‡å“è³ª
  - [ ] 10.1 å–®å…ƒæ¸¬è©¦ï¼šJest + React Testing Libraryï¼ˆRendererï¼‰ã€Jestï¼ˆMainï¼‰ã€Mock Electron/OS/OpenAI
  - [ ] 10.2 æ•´åˆèˆ‡ E2Eï¼šIPC æ•´åˆã€ä¸‰å¤§æ ¸å¿ƒæµç¨‹ã€éš±ç§èˆ‡å®‰å…¨é©—è­‰ã€è·¨å¹³å°ç›¸å®¹æ€§

- [ ] 11. æ•ˆèƒ½èˆ‡ç™¼ä½ˆ
  - [ ] 11.1 æ•ˆèƒ½æœ€ä½³åŒ–ï¼šå•Ÿå‹•/è¨˜æ†¶é«”æœ€ä½³åŒ–ã€API å‘¼å«èˆ‡å¿«å–ã€è·¨å¹³å°æ•ˆèƒ½ç›£æ§ã€è³‡æºå‹•æ…‹èª¿æ•´
  - [ ] 11.2 æ‰“åŒ…èˆ‡åˆ†ç™¼ï¼šè·¨å¹³å°æ‰“åŒ…ã€è‡ªå‹•åŒ–å»ºç½®/åˆ†ç™¼ã€ç°½åèˆ‡é©—è­‰ã€å®‰è£èˆ‡æ›´æ–°æ©Ÿåˆ¶

---

## å››ã€æ¸¬è©¦è¨ˆç•«ï¼ˆç¯€é¸è‡ªè¨­è¨ˆ Testing Strategyï¼‰

- å–®å…ƒæ¸¬è©¦ï¼š
  - Rendererï¼šReact Testing Library
  - Mainï¼šæœå‹™æ¨¡çµ„ï¼ˆMock Electron/OSï¼‰ã€Mock OpenAI å›æ‡‰
- æ•´åˆæ¸¬è©¦ï¼š
  - Main â‡„ Renderer IPCã€ç†±éµã€æˆªåœ–ã€OpenAI æ•´åˆ
- ç«¯åˆ°ç«¯ï¼ˆSpectron æˆ– Playwright for Electronï¼‰ï¼š
  - å®Œæ•´ä½¿ç”¨è€…æµç¨‹ã€è·¨å¹³å°ç›¸å®¹æ€§ï¼ˆWin/macOS/Linuxï¼‰
- æ•ˆèƒ½æ¸¬è©¦ï¼š
  - å•Ÿå‹•æ™‚é–“ã€è¨˜æ†¶é«”æ´©æ¼ã€API å›æ‡‰æ™‚é–“ã€è·¨å¹³å°æ¯”è¼ƒ
- å®‰å…¨æ€§æ¸¬è©¦ï¼š
  - éš±ç§ï¼ˆç„¡è½åœ°ã€è¨˜æ†¶é«”æ¸…ç†ã€æµé‡åˆ†æï¼‰ã€ç†±éµå®‰å…¨ï¼ˆéµç›¤è¨˜éŒ„åµæ¸¬ã€ä½å±¤ç´šé‰¤å­é©—è­‰ã€ç³»çµ±æ—¥èªŒæª¢æŸ¥ï¼‰

---

## äº”ã€é—œéµè¨­å®šèˆ‡ç´„å®š

- å‰ç«¯è¨­å®šï¼šOpenAI APIé‡‘é‘°ã€åŸºç¤URLã€æ¨¡å‹é¸æ“‡ç­‰éƒ½å¯åœ¨æ‡‰ç”¨ç¨‹å¼è¨­å®šç•Œé¢ä¸­é…ç½®
- ä¸»è¦æª”æ¡ˆèˆ‡è·¯å¾‘ï¼ˆè¨ˆç•«ä¸­å·²æ¨™è¨»ï¼‰ï¼š
  - `./src/main/hotkey-manager.ts`
  - `./src/main/screenshot-manager.ts`
  - `./src/main/audio-manager.ts`
  - `./src/main/hide-manager.ts`
  - `./src/shared/openai-client.ts`
  - `./src/shared/types.ts`
  - `./src/renderer/components/TextInputComponent`

- å»ºç½®è¼¸å‡ºè·¯å¾‘ï¼š
  - ç”¢å‡ºè‡³ `dist/`ï¼ˆä¸»è¡Œç¨‹èˆ‡é è¼‰ï¼‰ï¼ŒRenderer ç”¢å‡ºè‡³ `dist/renderer/`

---

## æŠ€è¡“æ¶æ§‹èˆ‡é–‹ç™¼æŒ‡ä»¤

- **ç´”å‰ç«¯ Electron + TypeScript æ¶æ§‹**ï¼š
  - å–®ä¸€æ¡Œé¢æ‡‰ç”¨ç¨‹å¼ï¼Œå®Œå…¨ç„¡å¾Œç«¯æœå‹™
  - `OPENAI_API_KEY`ã€`OPENAI_BASE_URL`ã€æ¨¡å‹é¸æ“‡ç­‰éƒ½é€éå‰ç«¯ UI è¨­å®š
  - æ¨¡å‹æ¸…å–®ä½¿ç”¨ OpenAI SDK `client.models.list()` å‹•æ…‹å–å¾—
  - æ‰€æœ‰ AI è™•ç†éƒ½åœ¨ Main Process ä¸­ç›´æ¥å‘¼å« OpenAI API
  - APIè¨­å®šä½¿ç”¨ Electron safeStorage é€²è¡Œæœ¬åœ°åŠ å¯†å„²å­˜
  - å°è£ä½¿ç”¨ `electron-builder`ï¼šWindowsï¼ˆNSIS .exeï¼‰ã€macOSï¼ˆ.dmgï¼‰ã€Linuxï¼ˆAppImage/debï¼‰

### Packaging scripts

- `npm run dist` â€” Build + package for current platform using `electron-builder`.
- `npm run dist:win` â€” Build + package Windows (`--win --publish never`). Outputs NSIS installer under `release/`.
- `npm run dist:win:portable` â€” Build + package Windows Portable (`--win portable --publish never`). Outputs a single portable `.exe` under `release/` (no installer / no elevation / no autoâ€‘update).
- `npm run dist:mac` â€” Build + package macOS (`--mac --publish never`). Must run on macOS for DMG and signing.
- `npm run dist:mac:zip` â€” Build + package macOS ZIP (`--mac zip --publish never`).
- `npm run dist:linux` â€” Build + package Linux (`--linux --publish never`). Recommend running on Linux (or WSL2) for AppImage/deb.
- `npm run dist:linux:portable` â€” Build + package Linux AppImage only (`--linux AppImage --publish never`).

Packaging targets are defined in `electron-builder.json`:

```json
{
  "mac": { "target": ["dmg"], "category": "public.app-category.productivity" },
  "win": { "target": ["nsis", "portable"], "icon": "ghost.ico" },
  "mac": {
    "target": ["dmg", "zip"],
    "category": "public.app-category.productivity"
  },
  "linux": { "target": ["AppImage", "deb"] }
}
```

### Packaging assets

- Windows icon is set to `ghost.ico` at the repository root via `electron-builder.json` (`win.icon`).
- The icon file is also included at runtime through `extraResources` to allow the Tray and BrowserWindow to load it using `process.resourcesPath`.
- Runtime loading path helper is implemented in `src/main/main.ts` (`resolveAssetPath('ghost.ico')`), used for `BrowserWindow` `icon` and `Tray` icon.

- **é–‹ç™¼æŒ‡ä»¤**ï¼š
  - `npm install` - å®‰è£ä¾è³´
  - `npm run dev` - å•Ÿå‹•é–‹ç™¼æ¨¡å¼ï¼ˆé¦–æ¬¡ä½¿ç”¨å»ºè­°é€²å…¥è¨­å®šé¢æ¿è¨­å®š OpenAI APIï¼‰
  - `npm run build` - å»ºç½®ä¸¦æ‰“åŒ…æ‡‰ç”¨ç¨‹å¼
  - `npm run test` - åŸ·è¡Œæ¸¬è©¦

---

æœ¬æ–‡ä»¶ä½œç‚º Copilot çš„ä¸»è¦åƒç…§ï¼Œå”åŠ©åœ¨é–‹ç™¼éç¨‹ä¸­è‡ªå‹•å°é½Šéœ€æ±‚ï¼ˆR1â€“R8ï¼‰èˆ‡å¯¦ä½œè¨ˆç•«ï¼ˆ1â€“11ï¼‰ã€‚æäº¤ PR/Commit å‰ï¼Œè«‹å°ç…§æœ¬æ–‡ä»¶ä¹‹é©—æ”¶æ¨™æº–èˆ‡å°æ‡‰é–‹ç™¼é …ç›®ï¼Œç¢ºä¿ä¸€è‡´ã€‚
